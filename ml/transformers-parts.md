## Transformers 关键组件

---
### 引言

Transformers 是一种基于注意力机制的深度学习模型架构，它引入了自注意力机制（self-attention mechanism），通过直接学习输入序列中各个位置之间的依赖关系，实现了在序列数据上的并行化处理，从而在很大程度上提高了模型的效率和性能。

Transformers 模型由多层编码器和解码器组成，其中编码器用于将输入序列映射到隐藏表示，解码器用于根据编码器的输出生成目标序列。每个编码器和解码器层都由多个子层组成，包括自注意力层、前馈神经网络层和残差连接层，其中自注意力层是 Transformers 模型的核心组件之一。

学习到现在为止的很多




但是在学习 Transfomers 

在自注意力层中，输入序列的每个位置都被视为一个查询（query）、一个键（key）和一个值（value），通过计算查询与键的相似度来获取注意力分数，然后将注意力分数与值相乘并加权求和，得到每个位置的加权表示。这种机制使得模型能够在不同位置之间进行有效的信息交互，并且能够灵活地捕捉输入序列中的长距离依赖关系。
