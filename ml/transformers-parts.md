## Transformers 关键组件，以及对编码解码的另一种思考

---
### 关于认知和模型的联系和思考

Transformers 是一种基于注意力机制的深度学习模型架构，它引入了自注意力机制（self-attention mechanism），通过直接学习输入序列中各个位置之间的依赖关系，实现了在序列数据上的并行化处理，从而在很大程度上提高了模型的效率和性能。

Transformers 模型由多层编码器和解码器组成，其中编码器用于将输入序列映射到隐藏表示，解码器用于根据编码器的输出生成目标序列。每个编码器和解码器层都由多个子层组成，包括自注意力层、前馈神经网络层和残差连接层，其中自注意力层是 Transformers 模型的核心组件之一。

学习到现在为止的很多构架都是编码器解码器的组合，比如自编码器，比如生成对抗模型中的潜在空间变量生成图片的过程可以被看作是一种解码器。再进一步思考，其实机器学习中的几乎所有模型，都是一种先编码（模拟出某个内在的模式），然后再解码预测的过程。这个概念很重要。甚至在人的认知方面，我们的学习**对知识的吸收也必须是一种编码过程**。

昨天我刚刚读了兰陵王的文章，关于记忆的编码问题，短时记忆主要由听觉编码和视觉编码形成，长时记忆主要由语义编码所形成。在处理时间序列的模型中，虽然循环神经网络，LSTM等模型表现优秀，但是他们的限制就是这种短时记忆的原理，随着时间的进行，之前的记忆会被遗忘。最终起作用的信息，就只有最新的部分信息，一般来说LSTM对于20个步长以内的数据非常优秀，但是一旦拉长就不太行了，这也正是注意力机制和Transformer诞生的原因。

注意力机制，Transformer是长时间记忆的先驱，虽然 Attention is all you need 这句话太酷了，但是它其实隐藏了真实的意图，通过注意力达到的效果，其实应该是**知识关联**。虽然似乎一开始，注意力机制的出现是从图像来的灵感，但是从人类智能角度来说，所有的都回到了第一性原理，都是如此的关联。

在自注意力层中，输入序列的每个位置都被视为一个查询（query）、一个键（key）和一个值（value），通过计算查询与键的相似度来获取注意力分数，然后将注意力分数与值相乘并加权求和，得到每个位置的加权表示。这种机制使得模型能够在不同位置之间进行有效的信息交互，并且能够灵活地捕捉输入序列中的长距离依赖关系。Transformers 更是加入了位置编码，将循环神经网络的特别之处通过不同的方式引入进来，这宛如一个知识宫殿的建设，让知识的提取更加准确高效。

再说的远一点，这让我非常看好强化学习和遗传算法，因为从认知的角度，要想达到记忆，学习，理解的目的，最好的方法永远是主动学习，兴趣驱动，功利驱动，而强化学习正是这方面的体现。AGI的未来如何我不知道能否看到，但是一定离不开人类对自身的探索和认知的深入。

还是非常感谢兰陵王的启迪。

回归正题，拆解一下 Transformers 的关键组件。

### Tokenization

针对RNN 和 LSTM，Transformers 的进化来自于一个问题，为什么我们不把整个序列作为输入，从而摆脱隐藏层之间的依赖关系呢。这个想法很酷。因为这并不是一个现学现卖的世界，而是一个知识联系的世界。

如何存储知识？Tokenization。
