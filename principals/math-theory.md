## 线性代数

- 向量加减运算，即为向量的**空间移动操作**
- 向量乘除运算，似乎就是拉伸收缩，也就是**scaling**
- **标量和向量**的区别：
  - 标量：只有大小，没有方向。例如，温度、质量、时间等。
  - 向量：既有大小又有方向。例如，速度、力、加速度等。
  - 在数学中，标量通常是一个单独的数，可以是实数、复数、或者更加抽象的数。在向量空间中，标量用于描述向量的伸缩因子。

- **基向量 basis vectors**：一个向x方向的单位向量i，一个向y方向的单位向量j。
  - 向量的和 = **向量的线性组合ax+by**，a和b为基向量的倍数，两个向量的所有的线性组合叫做**span**，空间。
  - 基向量在矩阵里就是**单位矩阵**的表达。

- 空间，向量，点的思考
  - 无数的点，思考为线。一个向量上也有无数点，但我们思考为向量的终点。
  - 两个向量延展的空间，我们思考为一个平面span。
  - *共线*的两个向量，就只是一条直线了。
  - 三个向量构成线性组合空间，则是三维空间span。
  - 但是三个向量如果正好组合*落在一个平面上*也就是*共面*，那么则构成一个二维空间span。
  - 共线和共面的情况，意味着其中有冗余的向量，说明他们是**线性相关**的。

- **空间中一组基的严格定义**
  一组基是一个向量空间的最小集合，通过这些基向量的线性组合，可以生成该向量空间中的所有向量。这些基向量必须满足*线性无关性和生成整个空间*这两个关键条件。理解基的概念对于掌握线性代数和各种应用中的向量空间是至关重要的。

- **线性变化 Linear Transformations** = **矩阵**
  - 线性变换可以通过其对基向量的作用来完全确定。
  - 空间中，*原点不发生变化*，*线不会发生弯曲变化*。
  - 一个空间中的所有的矢量坐标都只需要用`i`和`j`坐标的四个数字来表示。那么二维空间中的线性变换，就是对x，和y的基于i和j的线性变换。
  - 如果`i`和`j`是线性相关的，比如[2, 1]和[-2, -1]，那么他们就会将空间变为一条直线。
  - **矩阵**就是由这些变换向量组成的，矩阵因此代表，对空间的线性变换的方法。
  - 矩阵是描述和实现线性变换的基本工具。通过矩阵乘法，我们可以具体地执行线性变换，并且可以通过矩阵的性质理解变换的几何意义。理解矩阵从线性变换的角度可以更直观地掌握其作用和应用。

```
   i  j
 [ 2, 1
   3, 4 ]
```
- **矩阵的乘法** = **矩阵的组合变换 Composition**
  - 矩阵的组合通过矩阵乘法实现，表示两个线性变换的复合。它使我们能够通过一系列基本变换来构建复杂的变换，并且具有明确的几何意义。矩阵乘法的结果可以用来描述这些复合变换的整体效果。
  - 矩阵A x 矩阵B = 复合矩阵C，这就像是`f(g(x))`的函数方法，我们要从B开始计算到A，也就是*从右到左*进行线性变换。

- **行列式 determinant**，线性代数的本质。
  - 面积和体积：对于二维矩阵，行列式的绝对值表示由矩阵定义的平行四边形的*面积*。对于三维矩阵，行列式的绝对值表示由矩阵定义的*平行六面体的体积*。
  - 变换性质：行列式可以表示线性变换的尺度变化。例如，如果一个线性变换由矩阵 A 描述，那么该变换在几何上会将单位面积或单位体积放大或缩小 
det(A) 倍。*行列式的计算值也会有负数的情况，这代表空间翻转了。*
  - 线性方程组的解：对于线性方程组 Ax=b，如果矩阵 A 的行列式不为零，则方程组有唯一解。如果行列式为零，方程组可能无解或者有无穷多解。
  - 特征值：矩阵 A 的行列式可以用于计算其特征值。特征值 λ 是使得矩阵 A−λI 的行列式为零的值。

- **逆矩阵，逆变换，column空间，零空间，秩rank**
  - **逆矩阵变换**是空间中恒等变换。对一个矩阵A执行逆变换得到的是单位矩阵。
  - 从空间变换的角度来看，矩阵 A 作用于向量 x 将它从原始位置变换到新的位置（例如，旋转、缩放、平移等）。逆矩阵 A^−1 的作用是将变换后的向量 y 逆向变换回原始位置 x。就像是回到过去。
  - **列向量空间**：给定一个矩阵A，列空间是由 A 的所有列向量组成的向量空间。具体来说，列空间是所有可以表示为 A 的列向量的线性组合的集合。如果列向量线性独立，列空间的维度等于列向量的个数（即矩阵的列数）。如果列向量线性相关，列空间的维度小于列向量的个数。
  - **维度（也称为秩，rank）**描述了列空间的维度，即*最大线性无关列向量的个数*。在变换的角度来看，如果矩阵的列向量线性独立，那么该变换可以覆盖到整个目标空间；如果线性相关，那么变换的结果会限制在一个低维空间中。
  - **零空间（Null Space），也称为核（Kernel）**：矩阵 A 的零空间是由所有被矩阵 A 映射到零向量的 n 维向量组成的集合。从空间变换的角度来看，零空间表示了在变换 A 下被压缩到零向量的所有向量。这些向量通过矩阵 A 的变换后失去了所有的方向和大小信息，被映射到原点。总之，零空间是矩阵变换中被映射到零向量的所有向量的集合。从空间变换的角度来看，它描述了变换中被完全压缩的方向或维度。理解零空间有助于我们深入了解线性变换的性质，特别是在分析矩阵的解集、自由度和奇异性方面。

- **矩阵空间可逆的条件**
  - 1. 线性独立性
    在线性代数中，一个矩阵 A 是可逆的（存在逆矩阵）当且仅当它的列向量（或行向量）是线性独立的。从空间变换的角度来看，这意味着矩阵 A 代表的变换不能将非零向量映射为零向量，也不能将多个不同的向量映射为同一个向量。
  - 2. 行列式非零
    行列式的几何解释与体积有关。对于矩阵 A ，行列式 det(A) 可以看作是变换 A 作用于单位立方体时所产生的新立方体的体积的缩放因子。若 det(A) 不等于零，这表示变换 A 保持了 n 维空间的体积，且没有压缩到低维空间。从空间变换的角度来看，表示 A 不会将整个空间压缩到低维度或单一平面，这样的变换是可逆的，因为可以找到唯一的逆变换来恢复原始空间。如果 det(A) = 0，则 A 将空间压缩到低维空间或单一平面，无法通过逆变换恢复原始空间。这意味着 A 是奇异的，没有逆矩阵。
  - 3. 双射性（Bijectivity）
    矩阵对应的线性变换必须是双射的，即变换后每一个向量都可以唯一确定原始向量。
  - 这让我想起三体中的二向箔就是将三维空间压缩为二维平面，并且不可逆。
  - 比如一个3x3矩阵，如果第三列都为零，则导致第三个维度的分量消失，这样的变换，会将三维空间压缩到一个二维平面。并且无法还原为原本的唯一的三维空间。

- 在线性代数中，**叉积（Cross Product）**是针对三维向量的一种操作。给定两个向量 a 和 b，其叉积 a×b 是一个新的向量，该向量满足以下条件：
  - 垂直性：a×b 垂直于 a 和 b 组成的平面。
  - 大小：a×b 的大小等于 a 和 b 的大小与它们之间夹角的正弦值的乘积，即 ∣a×b∣=∣a∣∣b∣sin(θ)。
  - 方向：使用右手定则确定方向。
  - **对偶向量（covector）**：是线性函数，将向量映射到一个实数，通常用行向量表示。对偶向量作用于向量时，通过内积操作得到一个实数：w(v)=ax+by

- **基础变换**
  - 从空间变换的角度来看，线性代数中的基础变换对应于对向量空间中的基向量进行的操作。
  - 基础行变换不会改变空间的维度，但一些更复杂的操作，例如添加或删除向量、合并向量、投影变换和拉伸/压缩，可以改变向量空间的维度。这些操作在更广泛的线性代数应用中起着关键作用，例如在主成分分析（PCA）中，通过投影和降维来简化数据结构。

## 特征向量（Eigenvector）和特征值（Eigenvalue）

特征向量和特征值是线性代数中的重要概念，特别是在矩阵的分析中。它们在多个领域中有广泛的应用，包括物理学、统计学、工程学、计算机科学等。

特征向量是一个非零向量，当它被一个方阵（即一个线性变换）作用时，其方向保持不变。换句话说，特征向量在这个变换下只是被拉伸或压缩，而不会改变方向。

数学上，如果 A 是一个 n x n 的方阵，v 是一个非零向量，并且存在一个标量 λ，使得：

Av = λv

那么 v 就是矩阵 A 的特征向量，λ 是对应的特征值。

特征值是一个标量，它表示特征向量在经过线性变换 A 后被拉伸或压缩的比例。对于特征向量 v 来说，特征值 λ 满足：

Av = λv

**从空间角度看**

1. **几何解释**：
   - 对于一个二维空间中的矩阵变换 A，特征向量是那些在变换后仍然保持在原来直线上（或者说方向不变）的向量。
   - 特征值则描述了这个方向的伸缩比例。例如，特征值 λ = 2 表示特征向量被拉长了一倍，λ = 0.5 表示特征向量被压缩了一半。

2. **线性变换的影响**：
   - 任何线性变换都可以看作是对空间中的向量进行旋转、拉伸或压缩。特征向量指向那些不改变方向的特定方向，而特征值则告诉我们这些方向上的缩放因子。

3. **特征空间**：
   - 如果一个矩阵有 n 个线性独立的特征向量，这些特征向量形成的空间称为矩阵的特征空间。这个特征空间可以帮助我们理解和分解复杂的线性变换。
   - 对于对称矩阵，特征向量是正交的，可以用来对矩阵进行对角化，即将矩阵表示为特征向量基下的对角矩阵形式，从而简化许多计算问题。

---
领域联系：

1. 线性代数
- **特征向量**：矩阵变换下不变方向的向量。
- **特征值**：特征向量方向上的缩放比例。

2. 机器学习
- **数据降维**：PCA 中特征向量定义新的坐标轴，特征值表示方向上的方差。
- **特征选择和提取**：LDA 和 CNN 中用于选择和提取重要特征。
- **数据结构分析**：协方差矩阵的特征向量和特征值用于理解数据分布。

3. 神经网络
- **权重矩阵分析**：理解模型的表达能力，通过特征分解分析权重矩阵。
- **特征表示和嵌入**：学习数据的特征表示，嵌入空间中的方向和重要性。
- **稳定性和收敛性**：Hessian 矩阵的特征值用于分析训练过程的稳定性。
- **模型压缩和加速**：低秩近似和 SVD 技术实现模型压缩。
- **解释性和可视化**：通过特征向量和特征值评估特征重要性和数据降维可视化。

4. 数据分析与统计
- **主成分分析 (PCA)**：识别数据中最大变异方向。
- **协方差矩阵**：分析数据特征之间的线性关系。

5. 物理学与工程
- **动力系统分析**：特征向量和特征值用于稳定性和振动分析。
- **结构工程**：分析建筑物和机械结构的模态和响应。

6. 经济与金融
- **风险管理**：协方差矩阵的特征值用于评估资产组合风险。
- **市场分析**：特征向量用于识别市场中主要影响因素。

特征向量和特征值在各个领域都帮助我们理解、分析和优化系统及数据的复杂性和行为。

**特征值的计算公式**

m +- (m^2 - p)^1/2

m加减根号，m的平方减去p。m是单位向量的值的平均。p是ad - bc。

## 抽象矢量空间

抽象矢量空间在数学中是一个用来描述和处理*向量*的概念。它可以帮助我们理解和操作各种不同类型的“向量”，不局限于物理空间中的几何向量。以下是一些更具**空间意义**的解释：

1. 向量：可以想象为一个有大小和方向的对象。例如，在二维空间中，向量可以是从原点到某个点的一条箭头。在抽象矢量空间中，向量不仅限于几何对象，还可以是多项式、函数等抽象对象。

2. 向量加法：两个向量的加法类似于在物理空间中把两个箭头首尾相接，然后从起点到终点画一条新的箭头。无论向量是什么类型，它们的加法都遵循这种直观的组合方式。

3. 标量乘法：将一个向量拉长或缩短。比如在物理空间中，如果你把一个向量放大两倍，箭头的长度会增加，但方向不变。同样地，在抽象矢量空间中，标量乘法改变向量的“大小”但不改变其本质。

抽象矢量空间的**特征**：

1. **维度**：维度表示向量空间的自由度或基向量的数量。比如，二维空间可以用两个基向量表示，三维空间则需要三个。在抽象矢量空间中，维度的概念依然成立，表示需要多少个独立的向量来描述空间中的所有向量。

2. **基向量**：基向量是用来描述整个空间的最基本的向量集合。所有空间中的向量都可以通过这些基向量的线性组合得到。比如，在二维空间中，基向量可以是 (1, 0) 和 (0, 1)。

3. **线性组合**：任何一个向量都可以通过若干基向量和一些标量相乘后相加得到。比如，二维空间中的任意向量都可以表示为两个基向量的某种加权和。

**空间的类型**：

1. 几何向量空间：这是最直观的向量空间，向量是物理空间中的箭头，描述大小和方向。比如二维或三维空间中的向量。

2. 多项式空间：这里的向量是多项式。比如，所有次数不超过 n 的多项式可以构成一个向量空间。向量加法是多项式的加法，标量乘法是多项式的系数乘法。

3. 函数空间：在这个空间中，向量是函数。比如，所有从实数域到实数域的连续函数可以构成一个向量空间。向量加法是函数的加法，标量乘法是函数值的数乘。

**应用**

- 物理学：向量空间用来描述物体的运动和力的相互作用。
- 计算机图形学：向量空间帮助处理和变换图形。
- 统计学：向量空间用于处理数据和构建统计模型。
- 工程学：在信号处理和控制系统中，向量空间理论被广泛应用。

通过这种方式，抽象矢量空间可以帮助我们在不同的数学和应用领域中以统一的方式处理和理解各种不同的“向量”对象。

## 微积分

微积分是数学的一个分支，主要研究连续变化的量。它分为微分和积分两部分：

1. **微分**：研究函数的变化率，即如何计算函数在某一点处的瞬时变化率。主要内容包括导数和微分方程。
2. **积分**：研究函数的累积量，即如何计算函数在某区间内的累积值。主要内容包括定积分和不定积分。

微积分的本质在于理解和描述变化与累积的关系。微分用于描述瞬时变化（如速度、加速度），积分用于描述总量的累积（如面积、体积）。具体来说：

- **微分的本质**：通过导数来描述函数在某一点的变化率。
- **积分的本质**：通过定积分来描述函数在某一区间内的累积量。

## 中心极限定理

中心极限定理（Central Limit Theorem）是统计学中的一条重要定理，指出当从一个总体中抽取大量*独立同分布*的样本并计算其均值时，这些样本*均值的分布*将近似于正态分布，*即使原总体分布不是正态的*。

这一定理解释了*正态分布在自然界和统计学中的普遍性*。
